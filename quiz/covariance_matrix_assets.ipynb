{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance of one stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.14.5 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.2MB 43kB/s  eta 0:00:01   20% |██████▌                         | 2.5MB 15.5MB/s eta 0:00:01    27% |████████▉                       | 3.3MB 19.2MB/s eta 0:00:01    45% |██████████████▊                 | 5.6MB 24.7MB/s eta 0:00:01    75% |████████████████████████▏       | 9.2MB 24.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.18.1 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/11/09/e66eb844daba8680ddff26335d5b4fead77f60f957678243549a8dd4830d/pandas-0.18.1.tar.gz (7.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.3MB 72kB/s  eta 0:00:01  0% |▎                               | 71kB 18.4MB/s eta 0:00:01    14% |████▋                           | 1.1MB 17.9MB/s eta 0:00:01    31% |██████████                      | 2.3MB 22.7MB/s eta 0:00:01    47% |███████████████▎                | 3.5MB 25.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==2.2.3 (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/99/a6/8214b6564bf4ace9bec8a26e7f89832792be582c042c47c912d3201328a0/plotly-2.2.3.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 479kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4))\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5))\n",
      "Collecting zipline===1.2.0 (from -r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/15/d3/689f2a940478b82ac57c751a40460598221fd82b0449a7a8f7eef47a3bcc/zipline-1.2.0.tar.gz (659kB)\n",
      "\u001b[K    100% |████████████████████████████████| 665kB 756kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.6/site-packages (from pandas==0.18.1->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas==0.18.1->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: pip>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Collecting Logbook>=0.12.5 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/fc/3e7557ed1ef1bd4e3ee189fc670416abfc7192b550e8d3c1d858a63f41ab/Logbook-1.4.1.tar.gz (84kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-file>=1.4.1 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Collecting pandas-datareader<0.6,>=0.2.1 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/40/c5/cc720f531bbde0efeab940de400d0fcc95e87770a3abcd7f90d6d52a3302/pandas_datareader-0.5.0-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Requirement already satisfied: Cython>=0.25.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Collecting cyordereddict>=0.2.2 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/1a/364cbfd927be1b743c7f0a985a7f1f7e8a51469619f9fefe4ee9240ba210/cyordereddict-1.0.0.tar.gz (138kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bottleneck>=1.0.0 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting contextlib2>=0.4.0 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Collecting bcolz<1,>=0.12.1 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/8b/1ffa01f872cac36173c5eb95b58c01040d8d25f1b242c48577f4104cd3ab/bcolz-0.12.1.tar.gz (622kB)\n",
      "\u001b[K    100% |████████████████████████████████| 624kB 807kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Collecting multipledispatch>=0.4.8 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Requirement already satisfied: Mako>=1.0.1 in /opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Requirement already satisfied: sqlalchemy>=1.0.8 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "Collecting alembic>=0.7.7 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/44/32656b16e184713417fb55f406bfb1548fd00e3b36918e637ad1f1d98614/alembic-1.0.3.tar.gz (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 503kB/s eta 0:00:01    19% |██████                          | 194kB 22.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers>=1.4.4 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/13/f3/cf85f7c3a2dbd1a515d51e1f1676d971abe41bba6f4ab5443240d9a78e5b/sortedcontainers-2.1.0-py2.py3-none-any.whl\n",
      "Collecting intervaltree>=2.1.0 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/c1/450d109b70fa58ca9d77972b02f69222412f9175ccf99fdeaf167be9583c/intervaltree-2.1.0.tar.gz\n",
      "Collecting lru-dict>=1.1.4 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/00/a5/32ed6e10246cd341ca8cc205acea5d208e4053f48a4dced2b1b31d45ba3f/lru-dict-1.1.6.tar.gz\n",
      "Collecting empyrical>=0.4.2 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/55/a01b05162b764830dbbac868462f44cd847a5b6523a01ca9f955721819da/empyrical-0.5.0.tar.gz (49kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tables>=3.3.0 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/1b/21f4c7f296b718575c17ef25e61c05742a283c45077b4c8d5a190b3e0b59/tables-3.4.4-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K    99% |████████████████████████████████| 3.8MB 25.7MB/s eta 0:00:01    45% |██████████████▋                 | 1.7MB 22.7MB/s eta 0:00:01    100% |████████████████████████████████| 3.8MB 139kB/s \n",
      "\u001b[?25hRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 3))\n",
      "Collecting requests-ftp (from pandas-datareader<0.6,>=0.2.1->zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/ca/14b2ad1e93b5195eeaf56b86b7ecfd5ea2d5754a68d17aeb1e5b9f95b3cf/requests-ftp-0.3.1.tar.gz\n",
      "Collecting python-editor>=0.3 (from alembic>=0.7.7->zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/65/1e/adf6e000ea5dc909aa420352d6ba37f16434c8a3c2fa030445411a1ed545/python-editor-1.0.3.tar.gz\n",
      "Building wheels for collected packages: pandas, plotly, zipline, Logbook, cyordereddict, bottleneck, bcolz, alembic, intervaltree, lru-dict, empyrical, requests-ftp, python-editor\n",
      "  Running setup.py bdist_wheel for pandas ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a3/08/c3/8fdd52954d4b415624cff43c6dd32a22bac90306976a98f4af\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/54/81/dd92d5b0858fac680cd7bdb8800eb26c001dd9f5dc8b1bc0ba\n",
      "  Running setup.py bdist_wheel for zipline ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5d/20/7d/b48368c8634b1cb6cc7232833b2780a265d4217c0ad2e3d24c\n",
      "  Running setup.py bdist_wheel for Logbook ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/13/e9/88e9e8184d89671ffc754dc80f5eb01dabd72071bdb802c5d1\n",
      "  Running setup.py bdist_wheel for cyordereddict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0b/9d/8b/5bf3e22c1edd59b50f11bb19dec9dfcfe5a479fc7ace02b61f\n",
      "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
      "  Running setup.py bdist_wheel for bcolz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c5/cc/1b/2cf1f88959af5d7f4d449b7fc6c9452d0ecbd86fd61a9ee376\n",
      "  Running setup.py bdist_wheel for alembic ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/57/58/91/31e495c790b05e82563181064a9670168d7eeb817e5595e3c3\n",
      "  Running setup.py bdist_wheel for intervaltree ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6b/cf/b0/f7ef2d0f504d26f3e9e70c2369e5725591ccfaf67d528fcbc5\n",
      "  Running setup.py bdist_wheel for lru-dict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b7/ef/06/fbdd555907a7d438fb33e4c8675f771ff1cf41917284c51ebf\n",
      "  Running setup.py bdist_wheel for empyrical ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/83/14/73/34fb27552601518d28bd0813d75124be76d94ab29152c69112\n",
      "  Running setup.py bdist_wheel for requests-ftp ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/98/32/37195e45a3392a73d9f65c488cbea30fe5bad76aaef4d6b020\n",
      "  Running setup.py bdist_wheel for python-editor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/36/e0/98/ba386b125a00ea9dd52e2c16aa2ec0adbbd639b84bfe2e001d\n",
      "Successfully built pandas plotly zipline Logbook cyordereddict bottleneck bcolz alembic intervaltree lru-dict empyrical requests-ftp python-editor\n",
      "Installing collected packages: numpy, pandas, plotly, Logbook, requests-file, requests-ftp, pandas-datareader, cyordereddict, bottleneck, contextlib2, bcolz, multipledispatch, python-editor, alembic, sortedcontainers, intervaltree, lru-dict, empyrical, tables, zipline\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: pandas 0.20.3\n",
      "    Uninstalling pandas-0.20.3:\n",
      "      Successfully uninstalled pandas-0.20.3\n",
      "  Found existing installation: plotly 2.0.15\n",
      "    Uninstalling plotly-2.0.15:\n",
      "      Successfully uninstalled plotly-2.0.15\n",
      "Successfully installed Logbook-1.4.1 alembic-1.0.3 bcolz-0.12.1 bottleneck-1.2.1 contextlib2-0.5.5 cyordereddict-1.0.0 empyrical-0.5.0 intervaltree-2.1.0 lru-dict-1.1.6 multipledispatch-0.6.0 numpy-1.14.5 pandas-0.18.1 pandas-datareader-0.5.0 plotly-2.2.3 python-editor-1.0.3 requests-file-1.4.3 requests-ftp-0.3.1 sortedcontainers-2.1.0 tables-3.4.4 zipline-1.2.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zipline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7bd1771c8e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mquiz_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/quiz_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEquity\u001b[0m  \u001b[0;31m# Required for USEquityPricing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUSEquityPricing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'zipline'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import quiz_helper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import quiz_helper\n",
    "from zipline.data import bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ZIPLINE_ROOT'] = os.path.join(os.getcwd(), '..', '..','data','module_4_quizzes_eod')\n",
    "ingest_func = bundles.csvdir.csvdir_equities(['daily'], quiz_helper.EOD_BUNDLE_NAME)\n",
    "bundles.register(quiz_helper.EOD_BUNDLE_NAME, ingest_func)\n",
    "print('Data Registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import AverageDollarVolume\n",
    "from zipline.utils.calendars import get_calendar\n",
    "\n",
    "universe = AverageDollarVolume(window_length=120).top(500) \n",
    "trading_calendar = get_calendar('NYSE') \n",
    "bundle_data = bundles.load(quiz_helper.EOD_BUNDLE_NAME)\n",
    "engine = quiz_helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data¶\n",
    "With the pipeline engine built, let's get the stocks at the end of the period in the universe we're using. We'll use these tickers to generate the returns data for the our risk model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_end_date = pd.Timestamp('2016-01-05', tz='UTC')\n",
    "\n",
    "universe_tickers = engine\\\n",
    "    .run_pipeline(\n",
    "        Pipeline(screen=universe),\n",
    "        universe_end_date,\n",
    "        universe_end_date)\\\n",
    "    .index.get_level_values(1)\\\n",
    "    .values.tolist()\n",
    "    \n",
    "universe_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(universe_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "data_portal = DataPortal(\n",
    "    bundle_data.asset_finder,\n",
    "    trading_calendar=trading_calendar,\n",
    "    first_trading_day=bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "    equity_minute_reader=None,\n",
    "    equity_daily_reader=bundle_data.equity_daily_bar_reader,\n",
    "    adjustment_reader=bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get pricing data helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quiz_helper import get_pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get pricing data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = \\\n",
    "    get_pricing(\n",
    "        data_portal,\n",
    "        trading_calendar,\n",
    "        universe_tickers,\n",
    "        universe_end_date - pd.DateOffset(years=5),\n",
    "        universe_end_date)\\\n",
    "    .pct_change()[1:].fillna(0) #convert prices into returns\n",
    "\n",
    "returns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at a two stock portfolio\n",
    "\n",
    "Let's pretend we have a portfolio of two stocks.  We'll pick Apple and Microsoft in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_col = returns_df.columns[3]\n",
    "msft_col = returns_df.columns[312]\n",
    "asset_return_1 = returns_df[aapl_col].rename('asset_return_aapl')\n",
    "asset_return_2 = returns_df[msft_col].rename('asset_return_msft')\n",
    "asset_return_df = pd.concat([asset_return_1,asset_return_2],axis=1)\n",
    "asset_return_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor returns\n",
    "Let's make up a \"factor\" by taking an average of all stocks in our list.  You can think of this as an equal weighted index of the 490 stocks, kind of like a measure of the \"market\".  We'll also make another factor by calculating the median of all the stocks.  These are mainly intended to help us generate some data to work with.  We'll go into how some common risk factors are generated later in the lessons.\n",
    "\n",
    "Also note that we're setting axis=1 so that we calculate a value for each time period (row) instead of one value for each column (assets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_return_1 = returns_df.mean(axis=1)\n",
    "factor_return_2 = returns_df.median(axis=1)\n",
    "factor_return_l = [factor_return_1, factor_return_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor exposures\n",
    "\n",
    "Factor exposures refer to how \"exposed\" a stock is to each factor.  We'll get into this more later.  For now, just think of this as one number for each stock, for each of the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For now, just assume that we're calculating a number for each \n",
    "stock, for each factor, which represents how \"exposed\" each stock is\n",
    "to each factor. \n",
    "We'll discuss how factor exposure is calculated later in the lessons.\n",
    "\"\"\"\n",
    "def get_factor_exposures(factor_return_l, asset_return):\n",
    "    lr = LinearRegression()\n",
    "    X = np.array(factor_return_l).T\n",
    "    y = np.array(asset_return.values)\n",
    "    lr.fit(X,y)\n",
    "    return lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_l = []\n",
    "for i in range(len(asset_return_df.columns)):\n",
    "    factor_exposure_l.append(\n",
    "        get_factor_exposures(factor_return_l,\n",
    "                             asset_return_df[asset_return_df.columns[i]]\n",
    "                            ))\n",
    "    \n",
    "factor_exposure_a = np.array(factor_exposure_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"factor_exposures for asset 1 {factor_exposure_a[0]}\")\n",
    "print(f\"factor_exposures for asset 2 {factor_exposure_a[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Variance of stock 1\n",
    "\n",
    "Calculate the variance of stock 1.  \n",
    "$\\textrm{Var}(f_{1}) = \\beta_{1,1}^2 \\textrm{Var}(f_{1}) + \\beta_{1,2}^2 \\textrm{Var}(f_{2}) + 2\\beta_{1,1}\\beta_{1,2}\\textrm{Cov}(f_{1},f_{2}) + \\textrm{Var}(s_{1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_1_1 = factor_exposure_a[0][0]\n",
    "factor_exposure_1_2 = factor_exposure_a[0][1]\n",
    "common_return_1 = factor_exposure_1_1 * factor_return_1 + factor_exposure_1_2 * factor_return_2\n",
    "specific_return_1 = asset_return_1 - common_return_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covm_f1_f2 = np.cov(factor_return_1,factor_return_2,ddof=1) #this calculates a covariance matrix\n",
    "# TODO: get the variance of each factor, and covariances from the covariance matrix covm_f1_f2\n",
    "var_f1 = #...\n",
    "var_f2 = #...\n",
    "cov_f1_f2 = #...\n",
    "\n",
    "# TODO: calculate the specific variance.  \n",
    "var_s_1 = # ...\n",
    "\n",
    "# TODO: calculate the variance of asset 1 in terms of the factors and specific variance\n",
    "var_asset_1 = # ...\n",
    "print(f\"variance of asset 1: {var_asset_1:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 2: Variance of stock 2\n",
    "Calculate the variance of stock 2.  \n",
    "$\\textrm{Var}(f_{2}) = \\beta_{2,1}^2 \\textrm{Var}(f_{1}) + \\beta_{2,2}^2 \\textrm{Var}(f_{2}) + 2\\beta_{2,1}\\beta_{2,2}\\textrm{Cov}(f_{1},f_{2}) + \\textrm{Var}(s_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_2_1 = factor_exposure_a[1][0]\n",
    "factor_exposure_2_2 = factor_exposure_a[1][1]\n",
    "common_return_2 = factor_exposure_2_1 * factor_return_1 + factor_exposure_2_2 * factor_return_2\n",
    "specific_return_2 = asset_return_2 - common_return_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we already calculated the variance and covariances of the factors\n",
    "\n",
    "# TODO: calculate the specific variance of asset 2\n",
    "var_s_2 = # ...\n",
    "\n",
    "# TODO: calcualte the variance of asset 2 in terms of the factors and specific variance\n",
    "var_asset_2 = # ...\n",
    "            \n",
    "print(f\"variance of asset 2: {var_asset_2:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 3: Covariance of stocks 1 and 2\n",
    "Calculate the covariance of stock 1 and 2.  \n",
    "$\\textrm{Cov}(f_{1},f_{2}) = \\beta_{1,1}\\beta_{2,1}\\textrm{Var}(f_{1}) + \\beta_{1,1}\\beta_{2,2}\\textrm{Cov}(f_{1},f_{2}) + \\beta_{1,2}\\beta_{2,1}\\textrm{Cov}(f_{1},f_{2}) + \\beta_{1,2}\\beta_{2,2}\\textrm{Var}(f_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate the covariance of assets 1 and 2 in terms of the factors\n",
    "cov_asset_1_2 = # ...\n",
    "print(f\"covariance of assets 1 and 2: {cov_asset_1_2:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 4: Do it with Matrices!\n",
    "\n",
    "Create matrices $\\mathbf{F}$, $\\mathbf{B}$ and $\\mathbf{S}$, where  \n",
    "$\\mathbf{F}= \\begin{pmatrix}\n",
    "\\textrm{Var}(f_1) & \\textrm{Cov}(f_1,f_2) \\\\ \n",
    "\\textrm{Cov}(f_2,f_1) & \\textrm{Var}(f_2) \n",
    "\\end{pmatrix}$\n",
    "is the covariance matrix of factors,  \n",
    "\n",
    "$\\mathbf{B} = \\begin{pmatrix}\n",
    "\\beta_{1,1}, \\beta_{1,2}\\\\ \n",
    "\\beta_{2,1}, \\beta_{2,2}\n",
    "\\end{pmatrix}$ \n",
    "is the matrix of factor exposures, and  \n",
    "\n",
    "$\\mathbf{S} = \\begin{pmatrix}\n",
    "\\textrm{Var}(s_i) & 0\\\\ \n",
    "0 & \\textrm{Var}(s_j)\n",
    "\\end{pmatrix}$\n",
    "is the matrix of specific variances.  \n",
    "\n",
    "Then calculate $\\mathbf{BFB}^T$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: covariance matrix of factors\n",
    "F = # ...\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: matrix of factor exposures\n",
    "B = # ...\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint: for diagonal matrices\n",
    "You can try using [numpy.diag](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.diag.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: matrix of specific variances\n",
    "S = # ...\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: covariance matrix of assets\n",
    "covm_assets = # ...\n",
    "print(f\"covariance matrix of assets 1 and 2 \\n{covm_assets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "[Solution notebook](covariance_matrix_assets_solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
